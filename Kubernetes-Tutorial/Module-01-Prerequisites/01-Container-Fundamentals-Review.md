# ğŸ“¦ **Module 1: Container Fundamentals Review**
## Deep Dive into Containerization for Kubernetes

---

## ğŸ“‹ **Module Overview**

**Duration**: 2-3 hours  
**Prerequisites**: Basic understanding of virtualization concepts  
**Learning Objectives**: Master container fundamentals essential for Kubernetes

---

## ğŸ¯ **Learning Objectives**

By the end of this module, you will:
- Understand container architecture and lifecycle
- Master Docker commands and best practices
- Analyze your e-commerce application's containerization
- Optimize container images for production
- Understand container security fundamentals
- Apply container concepts to Kubernetes preparation

---

## ğŸ“š **Theory Section: Container Fundamentals**

### **What Are Containers?**

Containers are lightweight, portable, and self-contained units that package applications and their dependencies. Unlike virtual machines that virtualize entire operating systems, containers share the host OS kernel while providing isolated user spaces.

#### **Key Characteristics:**
- **Isolation**: Each container has its own filesystem, network, and process space
- **Portability**: Containers run consistently across different environments
- **Efficiency**: Share the host OS kernel, reducing resource overhead
- **Scalability**: Can be quickly started, stopped, and replicated

### **Container vs Virtual Machine**

| Aspect | Containers | Virtual Machines |
|--------|------------|------------------|
| **OS** | Share host OS kernel | Full OS per VM |
| **Size** | MBs (lightweight) | GBs (heavy) |
| **Startup Time** | Seconds | Minutes |
| **Resource Usage** | Low | High |
| **Isolation** | Process-level | Hardware-level |
| **Portability** | High | Medium |

### **Container Architecture**

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Host Operating System                    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Container Runtime (Docker/containerd)                     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Container 1    â”‚  Container 2    â”‚  Container 3           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚   App     â”‚  â”‚  â”‚   App     â”‚  â”‚  â”‚   App     â”‚         â”‚
â”‚  â”‚   Libs    â”‚  â”‚  â”‚   Libs    â”‚  â”‚  â”‚   Libs    â”‚         â”‚
â”‚  â”‚   Runtime â”‚  â”‚  â”‚   Runtime â”‚  â”‚  â”‚   Runtime â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Container Lifecycle**

1. **Create**: Define container from image
2. **Start**: Begin execution
3. **Run**: Execute application
4. **Stop**: Gracefully terminate
5. **Remove**: Delete container instance

---

## ğŸ”§ **Hands-on Lab: Analyzing Your E-commerce Application**

### **Lab 1: Examining Your Docker Setup**

Let's analyze your existing e-commerce application's containerization:

```bash
# Navigate to your e-commerce project
cd /path/to/your/e-commerce

# Examine the backend Dockerfile
cat docker/Dockerfile.backend
```

#### **Backend Dockerfile Analysis**

**ğŸ“‹ Overview**: This is a multi-stage Dockerfile that creates a production-ready FastAPI backend container. It uses two stages: a builder stage for compiling dependencies and a production stage for the final runtime image.

**ğŸ” Detailed Line-by-Line Analysis**:

```dockerfile
# Multi-stage Dockerfile for Backend (FastAPI)
# Optimized for production with security best practices
```
**Explanation**: Comments explaining the purpose - this is a multi-stage build for production optimization and security.

```dockerfile
# Build stage - Creates a temporary environment for building
FROM python:3.11-slim as builder
```
**Explanation**: 
- `FROM`: Specifies the base image to start from
- `python:3.11-slim`: Official Python 3.11 image with minimal packages (slim variant reduces size)
- `as builder`: Names this stage "builder" for reference in later stages
- **Why slim?**: Reduces attack surface and image size by excluding development tools

```dockerfile
# Build arguments - Allow customization during build
ARG BUILD_DATE
ARG VCS_REF
ARG VERSION
```
**Explanation**:
- `ARG`: Defines build-time variables that can be passed during build
- `BUILD_DATE`: Timestamp when image was built (for traceability)
- `VCS_REF`: Git commit hash (for version tracking)
- `VERSION`: Application version (for release management)
- **Usage**: `docker build --build-arg VERSION=1.0.0 .`

```dockerfile
# Labels for metadata - Provide information about the image
LABEL maintainer="ecommerce-team@example.com" \
      org.opencontainers.image.title="E-Commerce Backend" \
      org.opencontainers.image.description="FastAPI backend for e-commerce application" \
      org.opencontainers.image.version=$VERSION \
      org.opencontainers.image.created=$BUILD_DATE \
      org.opencontainers.image.revision=$VCS_REF \
      org.opencontainers.image.source="https://gitlab.com/your-org/e-commerce"
```
**Explanation**:
- `LABEL`: Adds metadata to the image (following OCI standards)
- `maintainer`: Contact information for the image maintainer
- `org.opencontainers.image.*`: Standard OCI labels for image metadata
- `$VERSION`, `$BUILD_DATE`, `$VCS_REF`: References to ARG variables defined above
- **Benefits**: Enables image tracking, compliance, and automated tooling

```dockerfile
# Set environment variables - Optimize Python behavior
ENV PYTHONDONTWRITEBYTECODE=1 \    # Don't write .pyc files
    PYTHONUNBUFFERED=1 \           # Don't buffer stdout/stderr
    PIP_NO_CACHE_DIR=1 \           # Don't cache pip downloads
    PIP_DISABLE_PIP_VERSION_CHECK=1 # Skip pip version checks
```
**Explanation**:
- `ENV`: Sets environment variables for the container
- `PYTHONDONTWRITEBYTECODE=1`: Prevents Python from writing .pyc files (reduces image size)
- `PYTHONUNBUFFERED=1`: Ensures Python output is sent directly to terminal (better logging)
- `PIP_NO_CACHE_DIR=1`: Prevents pip from caching packages (reduces image size)
- `PIP_DISABLE_PIP_VERSION_CHECK=1`: Skips pip version checks (faster builds)
- **Backslash (\)**: Line continuation for multi-line ENV statements

```dockerfile
# Install system dependencies - Required for building Python packages
RUN apt-get update && apt-get install -y --no-install-recommends \
    build-essential \              # Compiler tools
    libpq-dev \                   # PostgreSQL development headers
    && rm -rf /var/lib/apt/lists/* # Clean up package cache
```
**Explanation**:
- `RUN`: Executes commands during image build
- `apt-get update`: Updates package list from repositories
- `apt-get install -y`: Installs packages without prompting (-y = yes to all)
- `--no-install-recommends`: Only installs essential packages (reduces size)
- `build-essential`: Includes gcc, g++, make (needed for compiling Python packages)
- `libpq-dev`: PostgreSQL development libraries (needed for psycopg2)
- `&& rm -rf /var/lib/apt/lists/*`: Removes package cache to reduce image size
- **Best Practice**: Combine commands with && to reduce layers

```dockerfile
# Create virtual environment - Isolate Python dependencies
RUN python -m venv /opt/venv
ENV PATH="/opt/venv/bin:$PATH"
```
**Explanation**:
- `python -m venv /opt/venv`: Creates Python virtual environment in /opt/venv
- **Why virtual env?**: Isolates dependencies from system Python
- `ENV PATH="/opt/venv/bin:$PATH"`: Adds virtual environment's bin directory to PATH
- **Result**: Python and pip commands will use the virtual environment

```dockerfile
# Copy requirements and install Python dependencies
COPY backend/requirements.txt /tmp/requirements.txt
RUN pip install --upgrade pip && \
    pip install -r /tmp/requirements.txt
```
**Explanation**:
- `COPY backend/requirements.txt /tmp/requirements.txt`: Copies requirements file to container
- **Why /tmp?**: Temporary location, will be cleaned up
- `pip install --upgrade pip`: Updates pip to latest version
- `pip install -r /tmp/requirements.txt`: Installs all Python dependencies
- **Layer Optimization**: Copy requirements first, then install (enables Docker layer caching)

```dockerfile
# Production stage - Final, optimized image
FROM python:3.11-slim as production
```
**Explanation**:
- `FROM python:3.11-slim as production`: Starts new stage with fresh base image
- **Why new stage?**: Builder stage included build tools we don't need in production
- **Result**: Smaller, more secure production image

```dockerfile
# Install runtime dependencies - Only what's needed to run
RUN apt-get update && apt-get install -y --no-install-recommends \
    libpq5 \                      # PostgreSQL runtime library
    curl \                        # For health checks
    && rm -rf /var/lib/apt/lists/* \
    && apt-get clean
```
**Explanation**:
- `libpq5`: PostgreSQL client library (runtime dependency, not dev headers)
- `curl`: HTTP client for health checks
- `apt-get clean`: Additional cleanup of package cache
- **Security**: Only runtime dependencies, no build tools

```dockerfile
# Create non-root user - Security best practice
RUN groupadd -r appuser && useradd -r -g appuser appuser
```
**Explanation**:
- `groupadd -r appuser`: Creates system group "appuser" (-r = system group)
- `useradd -r -g appuser appuser`: Creates system user "appuser" in group "appuser"
- **Security Benefit**: Prevents privilege escalation if container is compromised
- **Best Practice**: Never run containers as root in production

```dockerfile
# Copy virtual environment from builder stage
COPY --from=builder /opt/venv /opt/venv
ENV PATH="/opt/venv/bin:$PATH"
```
**Explanation**:
- `COPY --from=builder`: Copies files from the "builder" stage
- `/opt/venv /opt/venv`: Source and destination paths
- **Result**: Production image gets compiled Python packages without build tools
- `ENV PATH="/opt/venv/bin:$PATH"`: Sets up PATH for virtual environment

```dockerfile
# Set working directory
WORKDIR /app
```
**Explanation**:
- `WORKDIR /app`: Sets /app as the current working directory
- **Effect**: All subsequent commands run from /app
- **Benefit**: Consistent file paths, easier debugging

```dockerfile
# Copy application code
COPY backend/ .
```
**Explanation**:
- `COPY backend/ .`: Copies entire backend directory to current working directory (/app)
- **Note**: This copies source code, not the requirements.txt (already handled)
- **Layer Caching**: This layer will be rebuilt when source code changes

```dockerfile
# Create necessary directories and set permissions
RUN mkdir -p uploads/products logs && \
    chown -R appuser:appuser /app
```
**Explanation**:
- `mkdir -p uploads/products logs`: Creates directory structure (-p creates parent directories)
- `chown -R appuser:appuser /app`: Changes ownership of /app to appuser
- **Security**: Ensures application can write to required directories
- **Structure**: uploads/products for file uploads, logs for application logs

```dockerfile
# Switch to non-root user - Security best practice
USER appuser
```
**Explanation**:
- `USER appuser`: Switches to non-root user for all subsequent commands
- **Security**: Container runs as unprivileged user
- **Effect**: If container is compromised, attacker has limited privileges

```dockerfile
# Health check - Monitor application health
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1
```
**Explanation**:
- `HEALTHCHECK`: Defines how Docker checks if container is healthy
- `--interval=30s`: Check every 30 seconds
- `--timeout=30s`: Wait 30 seconds for response
- `--start-period=5s`: Wait 5 seconds before first check (app startup time)
- `--retries=3`: Mark unhealthy after 3 consecutive failures
- `CMD curl -f http://localhost:8000/health || exit 1`: Health check command
- **Benefits**: Enables container orchestration health monitoring

```dockerfile
# Expose port - Document which port the app uses
EXPOSE 8000
```
**Explanation**:
- `EXPOSE 8000`: Documents that the application listens on port 8000
- **Note**: This doesn't actually publish the port (done with -p flag)
- **Purpose**: Documentation and metadata for orchestration tools

```dockerfile
# Default command - How to start the application
CMD ["uvicorn", "main:app", "--host", "0.0.0.0", "--port", "8000", "--workers", "4"]
```
**Explanation**:
- `CMD`: Defines the default command to run when container starts
- `["uvicorn", ...]`: Exec form (recommended) - runs command directly
- `main:app`: FastAPI app object in main.py file
- `--host 0.0.0.0`: Listen on all interfaces (not just localhost)
- `--port 8000`: Listen on port 8000
- `--workers 4`: Run 4 worker processes for better performance
- **Production Ready**: Optimized for production deployment

#### **Frontend Dockerfile Analysis**

```bash
# Examine the frontend Dockerfile
cat docker/Dockerfile.frontend
```

**ğŸ“‹ Overview**: This is a multi-stage Dockerfile for a React frontend application. It builds the React app in the first stage and serves it with Nginx in the production stage.

**ğŸ” Detailed Line-by-Line Analysis**:

```dockerfile
# Build Stage - Compile React application
FROM node:18-alpine AS builder
```
**Explanation**:
- `FROM node:18-alpine AS builder`: Uses Node.js 18 Alpine image as base
- `node:18-alpine`: Official Node.js 18 image with Alpine Linux (very small)
- `AS builder`: Names this stage "builder" for multi-stage build
- **Why Alpine?**: Extremely small (~5MB base), security-focused, minimal attack surface

```dockerfile
# Build arguments - Allow customization during build
ARG BUILD_DATE
ARG VCS_REF
ARG VERSION
ARG REACT_APP_API_URL=http://localhost:8000
ARG REACT_APP_API_BASE_URL=http://localhost:8000/api/v1
```
**Explanation**:
- `ARG BUILD_DATE`, `VCS_REF`, `VERSION`: Standard build metadata
- `ARG REACT_APP_API_URL=http://localhost:8000`: API URL for React app (default value)
- `ARG REACT_APP_API_BASE_URL=http://localhost:8000/api/v1`: API base URL (default value)
- **React Specific**: React apps use REACT_APP_ prefix for environment variables
- **Build-time**: These are set during docker build, not runtime

```dockerfile
# Labels for metadata
LABEL maintainer="ecommerce-team@example.com" \
      org.opencontainers.image.title="E-Commerce Frontend" \
      org.opencontainers.image.description="React frontend for e-commerce application" \
      org.opencontainers.image.version=$VERSION \
      org.opencontainers.image.created=$BUILD_DATE \
      org.opencontainers.image.revision=$VCS_REF \
      org.opencontainers.image.source="https://gitlab.com/your-org/e-commerce"
```
**Explanation**:
- Same OCI standard labels as backend
- **Consistency**: Maintains metadata standards across all images
- **Traceability**: Enables tracking and compliance across the application stack

```dockerfile
# Set working directory
WORKDIR /app
```
**Explanation**:
- `WORKDIR /app`: Sets /app as working directory for all subsequent commands
- **Effect**: All file operations will be relative to /app
- **Consistency**: Matches backend Dockerfile structure

```dockerfile
# Copy package files first - Leverage Docker layer caching
COPY frontend/package*.json ./
RUN npm ci --silent
```
**Explanation**:
- `COPY frontend/package*.json ./`: Copies package.json and package-lock.json
- **Why first?**: Dependencies change less frequently than source code
- **Layer Caching**: If source code changes, this layer won't be rebuilt
- `npm ci --silent`: Installs exact versions from package-lock.json
- `--silent`: Reduces build output noise
- **npm ci vs npm install**: ci is faster, more reliable for production builds

```dockerfile
# Copy source code
COPY frontend/ .
```
**Explanation**:
- `COPY frontend/ .`: Copies entire frontend directory to /app
- **After dependencies**: This layer will be rebuilt when source code changes
- **Efficiency**: Dependencies are already installed, so only source changes trigger rebuild

```dockerfile
# Set environment variables for build
ENV REACT_APP_API_URL=$REACT_APP_API_URL \
    REACT_APP_API_BASE_URL=$REACT_APP_API_BASE_URL \
    NODE_ENV=production
```
**Explanation**:
- `REACT_APP_API_URL=$REACT_APP_API_URL`: Uses build argument value
- `REACT_APP_API_BASE_URL=$REACT_APP_API_BASE_URL`: Uses build argument value
- `NODE_ENV=production`: Sets production mode for React build
- **React Build**: These variables are embedded in the built JavaScript bundle
- **Build-time**: Values are fixed at build time, not runtime

```dockerfile
# Build the application
RUN npm run build
```
**Explanation**:
- `npm run build`: Runs the build script defined in package.json
- **Result**: Creates optimized production build in /app/build directory
- **Optimization**: Minifies code, removes dev dependencies, optimizes assets
- **Output**: Static files ready for web server

```dockerfile
# Production Stage with Nginx - Serve static files
FROM nginx:1.25-alpine AS production
```
**Explanation**:
- `FROM nginx:1.25-alpine AS production`: Starts new stage with Nginx
- **Why Nginx?**: High-performance web server, excellent for static files
- **Alpine**: Small, secure base image
- **Separation**: Build tools (Node.js) not needed in production

```dockerfile
# Update packages and install curl for health checks
RUN apk update && apk upgrade && apk add --no-cache curl
RUN rm /etc/nginx/conf.d/default.conf
```
**Explanation**:
- `apk update && apk upgrade`: Updates Alpine package database and upgrades packages
- `apk add --no-cache curl`: Installs curl for health checks
- `--no-cache`: Doesn't store package cache (reduces image size)
- `rm /etc/nginx/conf.d/default.conf`: Removes default Nginx configuration
- **Security**: Updates packages to latest versions, removes unnecessary config

```dockerfile
# Copy nginx configuration files
COPY docker/nginx.conf /etc/nginx/conf.d/
COPY docker/security-headers.conf /etc/nginx/conf.d/
```
**Explanation**:
- `COPY docker/nginx.conf /etc/nginx/conf.d/`: Copies custom Nginx configuration
- `COPY docker/security-headers.conf /etc/nginx/conf.d/`: Copies security headers config
- **Custom Config**: Replaces default Nginx behavior with application-specific settings
- **Security**: Security headers protect against common web vulnerabilities

```dockerfile
# Copy built application from builder stage
COPY --from=builder /app/build /usr/share/nginx/html
```
**Explanation**:
- `COPY --from=builder`: Copies from the "builder" stage
- `/app/build /usr/share/nginx/html`: Source and destination paths
- **Nginx Default**: /usr/share/nginx/html is Nginx's default document root
- **Result**: Static React app is served by Nginx

```dockerfile
# Create non-root user for security
RUN addgroup -g 1001 -S nginx-user && \
    adduser -S -D -H -u 1001 -h /var/cache/nginx -s /sbin/nologin -G nginx-user nginx-user && \
    chown -R nginx-user:nginx-user /usr/share/nginx/html /var/cache/nginx /var/log/nginx /etc/nginx/conf.d
```
**Explanation**:
- `addgroup -g 1001 -S nginx-user`: Creates system group with GID 1001
- `adduser -S -D -H -u 1001 -h /var/cache/nginx -s /sbin/nologin -G nginx-user nginx-user`: Creates system user
  - `-S`: System user
  - `-D`: Don't assign password
  - `-H`: Don't create home directory
  - `-u 1001`: User ID 1001
  - `-h /var/cache/nginx`: Home directory
  - `-s /sbin/nologin`: No shell access
  - `-G nginx-user`: Add to nginx-user group
- `chown -R nginx-user:nginx-user /usr/share/nginx/html /var/cache/nginx /var/log/nginx /etc/nginx/conf.d`: Changes ownership
- **Security**: Nginx runs as unprivileged user

```dockerfile
# Switch to non-root user
USER nginx-user
```
**Explanation**:
- `USER nginx-user`: Switches to nginx-user for all subsequent commands
- **Security**: Container runs as non-root user
- **Principle**: Least privilege access

```dockerfile
# Health check
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \
  CMD curl -f http://localhost/ || exit 1
```
**Explanation**:
- Same health check pattern as backend
- `curl -f http://localhost/`: Tests if Nginx is serving content
- `-f`: Fail silently on HTTP errors
- **Monitoring**: Enables container orchestration health monitoring

```dockerfile
# Expose port
EXPOSE 80
```
**Explanation**:
- `EXPOSE 80`: Documents that Nginx listens on port 80 (HTTP)
- **Standard**: Port 80 is the standard HTTP port
- **Documentation**: Helps orchestration tools understand port requirements

```dockerfile
# Start nginx
CMD ["nginx", "-g", "daemon off;"]
```
**Explanation**:
- `CMD ["nginx", "-g", "daemon off;"]`: Starts Nginx in foreground mode
- `-g "daemon off;"`: Runs Nginx in foreground (required for containers)
- **Container Requirement**: Containers need a foreground process to stay running
- **Production Ready**: Optimized Nginx configuration for serving React app

### **Lab 2: Building and Running Containers**

**ğŸ“‹ Overview**: This lab demonstrates how to build Docker images and run containers with detailed command explanations.

**ğŸ” Detailed Command Analysis**:

```bash
# Build the backend image
docker build -f docker/Dockerfile.backend -t ecommerce-backend:latest .
```
**Explanation**:
- `docker build`: Command to build a Docker image from a Dockerfile
- `-f docker/Dockerfile.backend`: Specifies the Dockerfile path (default is ./Dockerfile)
- `-t ecommerce-backend:latest`: Tags the image with name "ecommerce-backend" and tag "latest"
- `.`: Build context (current directory) - all files in this directory are available to the build
- **Result**: Creates an image named ecommerce-backend:latest

```bash
# Build the frontend image
docker build -f docker/Dockerfile.frontend -t ecommerce-frontend:latest .
```
**Explanation**:
- Same pattern as backend build
- `-f docker/Dockerfile.frontend`: Uses the frontend-specific Dockerfile
- `-t ecommerce-frontend:latest`: Tags the frontend image
- **Multi-stage**: This will build both the Node.js builder stage and Nginx production stage

```bash
# List built images
docker images
```
**Explanation**:
- `docker images`: Lists all Docker images on the local system
- **Output shows**: Repository, tag, image ID, creation date, and size
- **Verification**: Confirms both images were built successfully

```bash
# Run the backend container
docker run -d \
  --name ecommerce-backend \
  -p 8000:8000 \
  -e DATABASE_URL=postgresql://postgres:admin@host.docker.internal:5432/ecommerce_db \
  ecommerce-backend:latest
```
**Explanation**:
- `docker run`: Command to create and start a new container
- `-d`: Run container in detached mode (background)
- `--name ecommerce-backend`: Assigns a name to the container for easy reference
- `-p 8000:8000`: Port mapping (host:container) - maps host port 8000 to container port 8000
- `-e DATABASE_URL=...`: Sets environment variable for database connection
- `postgresql://postgres:admin@host.docker.internal:5432/ecommerce_db`: Database connection string
  - `postgres:admin`: Username and password
  - `host.docker.internal`: Special hostname to access host machine from container
  - `5432`: PostgreSQL default port
  - `ecommerce_db`: Database name
- `ecommerce-backend:latest`: Image to run

```bash
# Run the frontend container
docker run -d \
  --name ecommerce-frontend \
  -p 3000:80 \
  ecommerce-frontend:latest
```
**Explanation**:
- `-p 3000:80`: Maps host port 3000 to container port 80 (Nginx default)
- **No environment variables**: Frontend doesn't need database connection
- **Port mapping**: Access frontend at http://localhost:3000

```bash
# Check running containers
docker ps
```
**Explanation**:
- `docker ps`: Lists currently running containers
- **Output shows**: Container ID, image, command, creation time, status, ports, names
- **Verification**: Confirms both containers are running successfully

```bash
# View container logs
docker logs ecommerce-backend
docker logs ecommerce-frontend
```
**Explanation**:
- `docker logs <container-name>`: Shows logs from a specific container
- **Backend logs**: Shows FastAPI startup messages, database connections, etc.
- **Frontend logs**: Shows Nginx startup messages
- **Debugging**: Essential for troubleshooting container issues

### **Lab 3: Container Inspection and Analysis**

**ğŸ“‹ Overview**: This lab demonstrates how to inspect and analyze running containers for debugging and monitoring purposes.

**ğŸ” Detailed Command Analysis**:

```bash
# Inspect container configuration
docker inspect ecommerce-backend
```
**Explanation**:
- `docker inspect <container-name>`: Returns detailed information about a container
- **Output includes**: Configuration, network settings, environment variables, mounts, etc.
- **JSON format**: Returns data in JSON format for programmatic access
- **Use cases**: Debugging configuration issues, understanding container setup
- **Example output**: Shows all container metadata, including IP address, port mappings, environment variables

```bash
# Check container resource usage
docker stats ecommerce-backend ecommerce-frontend
```
**Explanation**:
- `docker stats <container-names>`: Shows real-time resource usage statistics
- **Metrics shown**: CPU usage, memory usage, network I/O, block I/O
- **Real-time**: Updates continuously (use Ctrl+C to exit)
- **Monitoring**: Essential for performance analysis and capacity planning
- **Columns**: CONTAINER ID, NAME, CPU %, MEM USAGE / LIMIT, MEM %, NET I/O, BLOCK I/O, PIDs

```bash
# Execute commands inside running container
docker exec -it ecommerce-backend /bin/bash
```
**Explanation**:
- `docker exec`: Execute a command in a running container
- `-i`: Interactive mode (keeps STDIN open)
- `-t`: Allocate a pseudo-TTY (terminal)
- `ecommerce-backend`: Target container name
- `/bin/bash`: Command to execute (starts bash shell)
- **Result**: Opens an interactive bash session inside the container
- **Use cases**: Debugging, file system inspection, manual testing

```bash
# Check container processes
docker exec ecommerce-backend ps aux
```
**Explanation**:
- `docker exec ecommerce-backend ps aux`: Runs ps command inside the container
- `ps aux`: Lists all running processes with detailed information
- **Output shows**: Process ID, CPU usage, memory usage, command, etc.
- **Debugging**: Helps identify what processes are running inside the container
- **Security**: Verify only expected processes are running

```bash
# Check container network
docker network ls
docker network inspect bridge
```
**Explanation**:
- `docker network ls`: Lists all Docker networks
- **Default networks**: bridge (default), host, none
- **Custom networks**: Any user-created networks
- `docker network inspect bridge`: Shows detailed information about the bridge network
- **Bridge network**: Default network where containers communicate
- **Information includes**: Network ID, driver, IP range, connected containers
- **Debugging**: Helps understand container networking and connectivity issues

---

## ğŸ¯ **Practice Problems**

### **Problem 1: Container Optimization**

**Scenario**: Your e-commerce backend container is using too much memory. Optimize it.

**Requirements**:
1. Analyze current resource usage
2. Identify optimization opportunities
3. Implement multi-stage build improvements
4. Reduce image size by at least 30%

**Expected Output**:
- Optimized Dockerfile
- Before/after image size comparison
- Resource usage analysis

### **Problem 2: Container Security Hardening**

**Scenario**: Implement security best practices for your containers.

**Requirements**:
1. Run containers as non-root user
2. Implement proper health checks
3. Use minimal base images
4. Scan for vulnerabilities

**Expected Output**:
- Security-hardened Dockerfiles
- Vulnerability scan results
- Security configuration documentation

### **Problem 3: Container Networking**

**Scenario**: Set up communication between your frontend and backend containers.

**Requirements**:
1. Create a custom Docker network
2. Configure container-to-container communication
3. Implement proper service discovery
4. Test connectivity

**Expected Output**:
- Docker Compose configuration
- Network connectivity test results
- Service discovery setup

**ğŸ“‹ Detailed Solution with Line-by-Line Analysis**:

Create a `docker-compose.yml` file:

```yaml
# Docker Compose configuration for e-commerce application
# Enables container-to-container communication and service discovery
version: '3.8'
```
**Explanation**:
- `version: '3.8'`: Specifies Docker Compose file format version
- **Version 3.8**: Supports most modern Docker features including health checks, deploy configurations

```yaml
services:
  # Backend service definition
  backend:
    build:
      context: .
      dockerfile: docker/Dockerfile.backend
```
**Explanation**:
- `services:`: Defines the services (containers) in this application
- `backend:`: Service name (becomes hostname for service discovery)
- `build:`: Specifies how to build the image
- `context: .`: Build context (current directory)
- `dockerfile: docker/Dockerfile.backend`: Path to Dockerfile

```yaml
    environment:
      - DATABASE_URL=postgresql://postgres:admin@postgres:5432/ecommerce_db
      - SECRET_KEY=your-secret-key-here
      - DEBUG=false
```
**Explanation**:
- `environment:`: Sets environment variables for the container
- `DATABASE_URL=postgresql://postgres:admin@postgres:5432/ecommerce_db`: Database connection
  - `postgres:5432`: Uses service name "postgres" as hostname (service discovery)
  - `ecommerce_db`: Database name
- `SECRET_KEY`: Application secret key
- `DEBUG=false`: Production mode

```yaml
    ports:
      - "8000:8000"
```
**Explanation**:
- `ports:`: Maps host ports to container ports
- `"8000:8000"`: Host port 8000 maps to container port 8000
- **Access**: Backend accessible at http://localhost:8000

```yaml
    depends_on:
      - postgres
```
**Explanation**:
- `depends_on:`: Defines service dependencies
- `postgres`: Backend waits for postgres service to start
- **Order**: Ensures database is ready before backend starts

```yaml
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
```
**Explanation**:
- `healthcheck:`: Defines health check for the service
- `test: ["CMD", "curl", "-f", "http://localhost:8000/health"]`: Health check command
- `interval: 30s`: Check every 30 seconds
- `timeout: 10s`: Wait 10 seconds for response
- `retries: 3`: Mark unhealthy after 3 failures
- `start_period: 40s`: Wait 40 seconds before first check

```yaml
    networks:
      - ecommerce-network
```
**Explanation**:
- `networks:`: Specifies which networks this service connects to
- `ecommerce-network`: Custom network for service communication

```yaml
  # Frontend service definition
  frontend:
    build:
      context: .
      dockerfile: docker/Dockerfile.frontend
      args:
        - REACT_APP_API_URL=http://localhost:8000
        - REACT_APP_API_BASE_URL=http://localhost:8000/api/v1
```
**Explanation**:
- `frontend:`: Frontend service name
- `args:`: Build arguments passed to Dockerfile
- `REACT_APP_API_URL=http://localhost:8000`: API URL for React app
- `REACT_APP_API_BASE_URL=http://localhost:8000/api/v1`: API base URL

```yaml
    ports:
      - "3000:80"
    depends_on:
      - backend
```
**Explanation**:
- `"3000:80"`: Maps host port 3000 to container port 80 (Nginx)
- `depends_on: - backend`: Frontend waits for backend to be ready
- **Access**: Frontend accessible at http://localhost:3000

```yaml
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s
    networks:
      - ecommerce-network
```
**Explanation**:
- Similar health check pattern as backend
- `http://localhost/`: Tests Nginx serving content
- Same network configuration for service communication

```yaml
  # Database service definition
  postgres:
    image: postgres:13-alpine
```
**Explanation**:
- `postgres:`: Database service name (used in DATABASE_URL)
- `image: postgres:13-alpine`: Uses official PostgreSQL 13 Alpine image
- **Alpine**: Smaller, more secure base image

```yaml
    environment:
      - POSTGRES_DB=ecommerce_db
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=admin
```
**Explanation**:
- `POSTGRES_DB=ecommerce_db`: Creates database named ecommerce_db
- `POSTGRES_USER=postgres`: Creates user postgres
- `POSTGRES_PASSWORD=admin`: Sets password for postgres user
- **Security Note**: Use strong passwords in production

```yaml
    volumes:
      - postgres_data:/var/lib/postgresql/data
```
**Explanation**:
- `volumes:`: Defines persistent storage
- `postgres_data:/var/lib/postgresql/data`: Named volume for database persistence
- **Persistence**: Data survives container restarts

```yaml
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - ecommerce-network
```
**Explanation**:
- `pg_isready -U postgres`: PostgreSQL-specific health check
- `interval: 10s`: Check every 10 seconds (more frequent for database)
- `retries: 5`: More retries for database startup

```yaml
# Network definition
networks:
  ecommerce-network:
    driver: bridge
```
**Explanation**:
- `networks:`: Defines custom networks
- `ecommerce-network:`: Network name
- `driver: bridge`: Uses bridge network driver
- **Service Discovery**: Containers can reach each other by service name

```yaml
# Volume definition
volumes:
  postgres_data:
```
**Explanation**:
- `volumes:`: Defines named volumes
- `postgres_data:`: Volume name for database persistence
- **Management**: Docker manages the volume location

**ğŸ”§ Usage Commands**:

```bash
# Start all services
docker-compose up -d
```
**Explanation**:
- `docker-compose up`: Creates and starts all services
- `-d`: Detached mode (runs in background)
- **Result**: All containers start with proper networking

```bash
# Check service status
docker-compose ps
```
**Explanation**:
- `docker-compose ps`: Shows status of all services
- **Output**: Service name, command, state, ports

```bash
# View logs
docker-compose logs -f backend
```
**Explanation**:
- `docker-compose logs`: Shows logs from services
- `-f`: Follow logs in real-time
- `backend`: Specific service name

```bash
# Test connectivity
docker-compose exec backend curl http://postgres:5432
```
**Explanation**:
- `docker-compose exec`: Execute command in running service
- `backend`: Service name
- `curl http://postgres:5432`: Test connection to postgres service
- **Service Discovery**: Uses service name "postgres" as hostname

```bash
# Stop all services
docker-compose down
```
**Explanation**:
- `docker-compose down`: Stops and removes all services
- **Cleanup**: Removes containers, networks, but preserves volumes

---

## ğŸ“ **Assessment Quiz**

### **Multiple Choice Questions**

1. **What is the primary advantage of containers over virtual machines?**
   - A) Better security
   - B) Lower resource overhead
   - C) Easier management
   - D) Better performance

2. **In a multi-stage Docker build, what happens to the build stage?**
   - A) It becomes part of the final image
   - B) It's discarded after the build
   - C) It's cached for future builds
   - D) It's pushed to the registry

3. **What does the `HEALTHCHECK` instruction do?**
   - A) Monitors container resource usage
   - B) Checks if the application is responding
   - C) Validates container configuration
   - D) Tests network connectivity

### **Practical Questions**

4. **Explain the difference between `COPY` and `ADD` in Dockerfiles.**

5. **Why is it important to run containers as non-root users?**

6. **How does Docker layer caching work, and how can you optimize it?**

---

## ğŸš€ **Mini-Project: Container Optimization**

### **Project Requirements**

Optimize your e-commerce application's containerization for production deployment:

1. **Image Size Optimization**
   - Reduce backend image size by 40%
   - Reduce frontend image size by 50%
   - Implement proper layer caching

2. **Security Hardening**
   - Run all containers as non-root
   - Implement proper health checks
   - Use minimal base images
   - Scan for vulnerabilities

3. **Performance Optimization**
   - Optimize build times
   - Implement proper resource limits
   - Configure logging properly

### **Deliverables**

- Optimized Dockerfiles for both frontend and backend
- Docker Compose configuration for local development
- Security scan results and remediation
- Performance benchmarks (before/after)
- Documentation of optimization techniques used

---

## ğŸ¤ **Interview Questions and Answers**

### **Q1: Explain the difference between containers and virtual machines.**

**Answer**:
Containers and VMs differ fundamentally in their architecture:

**Containers**:
- Share the host OS kernel
- Lightweight (MBs in size)
- Fast startup (seconds)
- Process-level isolation
- High resource efficiency

**Virtual Machines**:
- Each VM has its own OS
- Heavy (GBs in size)
- Slower startup (minutes)
- Hardware-level isolation
- Higher resource overhead

**Real-world example**: In our e-commerce application, we can run multiple containers (frontend, backend, database) on a single host, whereas VMs would require separate OS instances for each service.

### **Q2: What are the benefits of multi-stage Docker builds?**

**Answer**:
Multi-stage builds provide several key benefits:

1. **Smaller Final Images**: Build dependencies are discarded
2. **Security**: Build tools aren't included in production images
3. **Efficiency**: Only runtime dependencies in final image
4. **Caching**: Each stage can be cached independently

**Example from our e-commerce backend**:
```dockerfile
# Build stage - includes build tools
FROM python:3.11-slim as builder
RUN apt-get install -y build-essential  # Build tools

# Production stage - only runtime dependencies
FROM python:3.11-slim as production
RUN apt-get install -y libpq5  # Only runtime library
```

### **Q3: How do you ensure container security in production?**

**Answer**:
Container security involves multiple layers:

1. **Base Image Security**:
   - Use minimal, official base images
   - Regularly update base images
   - Scan images for vulnerabilities

2. **Runtime Security**:
   - Run containers as non-root users
   - Implement proper resource limits
   - Use read-only filesystems where possible

3. **Network Security**:
   - Use custom networks
   - Implement network policies
   - Encrypt traffic between containers

4. **Secrets Management**:
   - Never hardcode secrets in images
   - Use external secret management
   - Rotate secrets regularly

**Example from our e-commerce app**:
```dockerfile
# Create non-root user
RUN groupadd -r appuser && useradd -r -g appuser appuser
USER appuser

# Health check for monitoring
HEALTHCHECK --interval=30s --timeout=30s --start-period=5s --retries=3 \
    CMD curl -f http://localhost:8000/health || exit 1
```

### **Q4: Explain Docker layer caching and how to optimize it.**

**Answer**:
Docker layer caching works by storing intermediate layers and reusing them when possible:

**How it works**:
- Each instruction creates a new layer
- Layers are cached based on instruction content
- If instruction changes, all subsequent layers are rebuilt

**Optimization strategies**:

1. **Order Instructions by Change Frequency**:
```dockerfile
# Copy package files first (changes less frequently)
COPY package*.json ./
RUN npm install

# Copy source code last (changes more frequently)
COPY . .
```

2. **Use .dockerignore**:
```dockerignore
node_modules
.git
*.md
.env
```

3. **Combine Related Commands**:
```dockerfile
# Good - single layer
RUN apt-get update && \
    apt-get install -y curl && \
    rm -rf /var/lib/apt/lists/*

# Bad - multiple layers
RUN apt-get update
RUN apt-get install -y curl
RUN rm -rf /var/lib/apt/lists/*
```

### **Q5: How would you troubleshoot a container that won't start?**

**Answer**:
Troubleshooting container startup issues involves systematic debugging:

1. **Check Container Logs**:
```bash
docker logs <container-name>
docker logs --tail 100 -f <container-name>
```

2. **Inspect Container Configuration**:
```bash
docker inspect <container-name>
```

3. **Test Image Locally**:
```bash
docker run -it <image-name> /bin/bash
```

4. **Check Resource Constraints**:
```bash
docker stats
docker system df
```

5. **Verify Dependencies**:
```bash
docker network ls
docker volume ls
```

**Common issues and solutions**:
- **Port conflicts**: Check if port is already in use
- **Missing environment variables**: Verify required env vars
- **File permissions**: Check file ownership and permissions
- **Resource limits**: Ensure sufficient memory/CPU
- **Network issues**: Verify network configuration

---

## ğŸ“ˆ **Real-world Scenarios**

### **Scenario 1: Production Container Deployment**

**Challenge**: Deploy your e-commerce application containers to production with zero downtime.

**Requirements**:
- Implement blue-green deployment
- Set up health checks and monitoring
- Configure proper logging
- Implement security best practices

**Solution Approach**:
1. Create production-optimized images
2. Set up container orchestration
3. Implement health checks and monitoring
4. Configure logging aggregation
5. Set up security scanning

### **Scenario 2: Container Performance Optimization**

**Challenge**: Your e-commerce application is experiencing performance issues in containers.

**Requirements**:
- Identify performance bottlenecks
- Optimize container resource usage
- Implement proper monitoring
- Scale containers effectively

**Solution Approach**:
1. Profile application performance
2. Optimize container images
3. Implement resource limits
4. Set up performance monitoring
5. Configure auto-scaling

---

## ğŸ¯ **Module Completion Checklist**

- [ ] Understand container architecture and lifecycle
- [ ] Analyze e-commerce application containerization
- [ ] Build and run containers successfully
- [ ] Implement container security best practices
- [ ] Optimize container images for production
- [ ] Complete practice problems
- [ ] Pass assessment quiz
- [ ] Complete mini-project
- [ ] Answer interview questions correctly
- [ ] Apply concepts to real-world scenarios

---

## ğŸ“š **Additional Resources**

### **Documentation**
- [Docker Official Documentation](https://docs.docker.com/)
- [Container Security Best Practices](https://cheatsheetseries.owasp.org/cheatsheets/Docker_Security_Cheat_Sheet.html)
- [Multi-stage Builds Guide](https://docs.docker.com/develop/dev-best-practices/dockerfile_best-practices/)

### **Tools**
- [Docker Desktop](https://www.docker.com/products/docker-desktop)
- [Docker Compose](https://docs.docker.com/compose/)
- [Trivy Security Scanner](https://trivy.dev/)
- [Dive Image Analyzer](https://github.com/wagoodman/dive)

### **Practice Platforms**
- [Play with Docker](https://labs.play-with-docker.com/)
- [Katacoda Docker Scenarios](https://www.katacoda.com/courses/docker)

---

## ğŸš€ **Next Steps**

1. **Complete this module** by working through all labs and assessments
2. **Set up your Kubernetes cluster** using the cluster setup guide
3. **Move to Module 2**: Linux System Administration
4. **Prepare for Kubernetes** by understanding container fundamentals

---

**Congratulations! You've completed the Container Fundamentals Review. You now have a solid foundation in containerization that will be essential for your Kubernetes journey. ğŸ‰**
